{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statswag.estimators import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Your Own Data\n",
    "\n",
    "The ultimate purpose of this package is to estimate the accuracy of labelers (and the true labels) for a dataset where the ground truth label of each data instance is unknown.  To use this package with your own data, you need only create the \"label matrix\" that represents your dataset.  That is, you need to create an array-like representation of the predicted labels from each labeler, for each data instance.\n",
    "\n",
    "Labels can be coded either as strings or as integers.  For example, if you have two classes \"malicious\" and \"benign,\" you can input the labels as strings, or say code the malicious as class \"1\" and benign as class \"0\", or vice versa.\n",
    "\n",
    "_Note: Possible classes are automatically inferred from the input, so errors in the input may produce invalid results._\n",
    "\n",
    "Suppose we have a dataset of 6 data instances, each labeled by 3 labelers.  Their output is as follows (assuming the ordering of data instances is the same for all labelers):\n",
    "1. Labeler 1: malicious, benign, benign, malicious, benign, malicious\n",
    "2. Labeler 2: malicious, benign, benign, malicious, malicious, malicious\n",
    "3. Labeler 3: malicious, benign, benign, malicious, malicious, benign\n",
    "\n",
    "The label matrix should be constructed so that the rows are the data instances (6 here) and the columns are the experts (3 here).  If we use 0 to code \"benign\" and 1 to code \"malicious\", the label matrix corresponding to this dataset is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracies': array([0.83848851, 0.83333333, 0.83848851]),\n",
       " 'labels': array([1, 0, 0, 1, 1, 1]),\n",
       " 'probs': None,\n",
       " 'class_names': array([0, 1])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data as integers\n",
    "X = [[1,1,1],\n",
    "    [0,0,0],\n",
    "    [0,0,0],\n",
    "    [1,1,1],\n",
    "    [0,1,1],\n",
    "    [1,1,0]]\n",
    "X = np.asarray(X)\n",
    "agree = Agreement()\n",
    "agree.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracies': array([0.81068241, 1.        , 0.81068241]),\n",
       " 'labels': array(['malicious', 'benign', 'benign', 'malicious', 'malicious',\n",
       "        'malicious'], dtype='<U9'),\n",
       " 'probs': None,\n",
       " 'class_names': array(['benign', 'malicious'], dtype='<U9')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data as strings\n",
    "X = [['malicious','malicious','malicious'],\n",
    "    ['benign','benign','benign'],\n",
    "    ['benign','benign','benign'],\n",
    "    ['malicious','malicious','malicious'],\n",
    "    ['benign','malicious','malicious'],\n",
    "    ['malicious','malicious','benign']]\n",
    "X = np.asarray(X)\n",
    "spectral = Spectral()\n",
    "spectral.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing data\n",
    "Some of the estimators (MajorityVote, IWMV, and MLE) can handle missing data (not all labelers label all data instances).  Missing labels need to be represented by ``nan``.  To include both integers (or strings) and ``nan`` in the same array, you must declare as an object array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['malicious', nan, 'malicious'],\n",
       "       ['benign', 'benign', 'benign'],\n",
       "       ['benign', 'benign', 'benign'],\n",
       "       ['malicious', 'malicious', 'malicious'],\n",
       "       ['benign', 'malicious', 'malicious'],\n",
       "       ['malicious', 'malicious', 'malicious']], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [['malicious',np.nan,'malicious'],\n",
    "    ['benign','benign','benign'],\n",
    "    ['benign','benign','benign'],\n",
    "    ['malicious','malicious','malicious'],\n",
    "    ['benign','malicious','malicious'],\n",
    "    ['malicious','malicious','malicious']]\n",
    "X = np.asarray(X,dtype=object)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracies': array([0.83333333, 1.        , 1.        ]),\n",
       " 'labels': array(['malicious', 'benign', 'benign', 'malicious', 'malicious',\n",
       "        'malicious'], dtype='<U9'),\n",
       " 'probs': array([[2.40442973e-10, 1.00000000e+00],\n",
       "        [1.00000000e+00, 0.00000000e+00],\n",
       "        [1.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 1.00000000e+00],\n",
       "        [0.00000000e+00, 1.00000000e+00],\n",
       "        [0.00000000e+00, 1.00000000e+00]]),\n",
       " 'class_names': array(['benign', 'malicious'], dtype=object)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLEOneParameterPerLabeler().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracies': [0.8333333333333334, 0.8, 0.8333333333333334],\n",
       " 'labels': ['malicious',\n",
       "  'benign',\n",
       "  'benign',\n",
       "  'malicious',\n",
       "  'malicious',\n",
       "  'malicious'],\n",
       " 'probs': None,\n",
       " 'class_names': array(['benign', 'malicious'], dtype=object)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MajorityVote().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracies': array([0.83333333, 1.        , 1.        ]),\n",
       " 'labels': array(['malicious', 'benign', 'benign', 'malicious', 'malicious',\n",
       "        'malicious'], dtype='<U9'),\n",
       " 'probs': None,\n",
       " 'class_names': array(['benign', 'malicious'], dtype=object)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IWMV().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
